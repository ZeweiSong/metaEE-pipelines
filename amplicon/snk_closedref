configfile: 'config.yaml'

import os
import sys
SAMPLES = []
workpath = config['workpath']
if workpath[-1] != '/':
	workpath = workpath + '/'
project = config['project']
for file in os.listdir(workpath + 'samples/'): # List all files under the folder. For PE data, one samples correspond to two files.
	string = file.split('.')
	if len(string) != 4: # You have to makesure that "." is not used in naming your samples. All files have the suffix .r1.fq.gz or .r2.fq.gz
		print('{0} contains illegal naming style, please check.'.format(file))
		sys.exit()
	esle:
		SAMPLES.append(string[0])
SAMPLES = tuple(set(SAMPLES))
SAMPLES = {i:i for i in SAMPLES}

fw=config['primers']['fw']
rv=config['primers']['rv']
base = {'A':'T','T':'A','C':'G','G':'C','R':'Y','Y':'R','K':'M','M':'K','S':'S','W':'W','B':'V','V':'B','D':'H','H':'D','N':'N'}
frc = ''.join([base[i] for i in list(fw)[0][::-1]])
rrc = ''.join([base[i] for i in list(rv)[0][::-1]])

rule target:
	input:
		combine_merged_biom			= workpath + 'concat/' + project + .merged.biom
		comebin_merged_taxa_biom	= workpath + 'concat/' + project + .merged.taxa.biom
		combine_merged_taxa_tsv		= workpath + 'concat/' + project + .merged.taxa.tsv
		combine_fwrv_biom			= workpath + 'concat/' + project + .fwrv.biom
		comebin_fwrv_taxa_biom		= workpath + 'concat/' + project + .fwrv.taxa.biom
		combine_fwrv_taxa_tsv		= workpath + 'concat/' + project + .fwrv.taxa.tsv

rule cutadapt:
	input:
		r1 = lambda wildcards: workpath + 'samples/' + SAMPLES[wildcards.sample] + '.r1.fq.gz',
		r2 = lambda wildcards: workpath + 'samples/' + SAMPLES[wildcards.sample] + '.r1.fq.gz'
	output:
		r1fw = workpath + 'cutadapt/{sample}.r1fw.fq',
		r2rv = workpath + 'cutadapt/{sample}.r2rv.fq',
		r1rv = workpath + 'cutadapt/{sample}.r1rv.fq',
		r2fw = workpath + 'cutadapt/{sample}.r2fw.fq'
	params:
		fw		= config['primers']['fw'],
		rv		= config['primers']['rv'],
		fwrc	= frc,
		rvrc	= rrv
		ascii	= config['ascii']
	log:
		workpath + 'logs/cutadapt/{sample}.log'
	threads: 2
	run:
		shell('cutadapt {input.r1} {input.r2} -g {params.fw} -a {params.rvrc} -G {params.rv} -A {params.fwrc} -n 2 --discard-untrimmed -e 0.1 -m 100 --quality-base {params.ascii} -j {threads} -o {output.r1fw} -p {output.r2rv} > {log}')
		shell('cutadapt {input.r1} {input.r2} -g {params.rv} -a {params.fwrc} -G {params.fw} -A {params.rvrc} -n 2 --discard-untrimmed -e 0.1 -m 100 --quality-base {params.ascii} -j {threads} -o {output.r1rv} -p {output.r2fw} >> {log}')

rule merge_r1:
	input:
		r1fw = workpath + 'cutadapt/{sample}.r1fw.fq',
		r2rv = workpath + 'cutadapt/{sample}.r2rv.fq'
	output:
		merged = workpath + 'merge_r1/{sample}.r1.assembled.fastq',
		r1fw = workpath + 'merge_r1/{sample}.r1.unassembled.forward.fastq',
		r2rv = workpath + 'merge_r1/{sample}.r1.unassembled.reverse.fastq',
		discard = temp(workpath + 'merge_r1/{sample}.r1.discard.fastq')
	params:
		sn = '{sample}.r1',
		ascii = config['ascii']
	threads: 2
	log:
		workpath + 'logs/merge_r1/{sample}.r1.log'
	run:
		shell('pear -f {input.r1fw} -r {input.r2rv} -o {params.sn} -b {params.ascii} -k -j {threads} > {log}')

rule merge_r2:
	input:
		r1rv = workpath + 'cutadapt/{sample}.r1rv.fq',
		r2fw = workpath + 'cutadapt/{sample}.r2fw.fq'
	output:
		merged = workpath + 'merge_r2/{sample}.r2.assembled.fastq',
		r2fw = workpath + 'merge_r2/{sample}.r2.unassembled.forward.fastq',
		r1rv = workpath + 'merge_r2/{sample}.r2.unassembled.reverse.fastq',
		discard = temp(workpath + 'merge_r2/{sample}.r2.discard.fastq')
	params:
		sn = '{sample}.r2',
		ascii = config['ascii']
	threads: 2
	log:
		workpath + 'logs/merge_r2/{sample}.r1.log'
	run:
		shell('pear -f {input.r2fw} -r {input.r1rv} -o {params.sn} -b {params.ascii} -k -j {threads} > {log}')

rule quality_control:
	input:
		merged_r1 	= workpath + 'merge_r1/{sample}.r1.assembled.fastq',
		r1fw 		= workpath + 'merge_r1/{sample}.r1.unassembled.forward.fastq',
		r2rv 		= workpath + 'merge_r1/{sample}.r1.unassembled.reverse.fastq',
		merged_r2 	= workpath + 'merge_r2/{sample}.r2.assembled.fastq',
		r2fw 		= workpath + 'merge_r2/{sample}.r2.unassembled.forward.fastq',
		r1rv 		= workpath + 'merge_r2/{sample}.r2.unassembled.reverse.fastq'
	output:
		merged_r1 	= workpath + 'quality_control/{sample}.r1.fq',
		r1fw 		= workpath + 'quality_control/{sample}.r1.fq',
		r2rv 		= workpath + 'quality_control/{sample}.r1.fq',
		merged_r2 	= workpath + 'quality_control/{sample}.r2.fq',
		r2fw 		= workpath + 'quality_control/{sample}.r2.fq',
		r1rv 		= workpath + 'quality_control/{sample}.r2.fq'
	log:
		workpath + 'logs/quality_control/{sample}.log'
	params:
		ascii = config['ascii']
	threads: 4
	run:
		shell('vsearch --fastq_filter {input.merged_r1} --fastqout {output.merged_r1} --fastq_maxee 1 --fastq_minlen 100 --fastq_ascii {params.ascii} --threads {threads} 2> {log}')
		shell('vsearch --fastq_filter {input.merged_r2} --fastqout {output.merged_r2} --fastq_maxee 1 --fastq_minlen 100 --fastq_ascii {params.ascii} --threads {threads} 2>> {log}')
		shell('vsearch --fastq_filter {input.r1fw} --reverse {input.r2rv} --fastqout {output.r1fw} --fastqout_rev {output.r2rv} --fastq_maxee 1 --fastq_minlen 100 --fastq_ascii {params.ascii} --threads {threads} 2>> {log}')
		shell('vsearch --fastq_filter {input.r1rv} --reverse {input.r2fw} --fastqout {output.r1rv} --fastqout_rev {output.r2fw} --fastq_maxee 1 --fastq_minlen 100 --fastq_ascii {params.ascii} --threads {threads} 2>> {log}')

# Trim off sequences not in database and convert to FASTA
rule trim_tail:
	input:
		merged_r1 	= workpath + 'quality_control/{sample}.r1.fq',
		r1fw 		= workpath + 'quality_control/{sample}.r1.fq',
		r2rv 		= workpath + 'quality_control/{sample}.r1.fq',
		merged_r2 	= workpath + 'quality_control/{sample}.r2.fq',
		r2fw 		= workpath + 'quality_control/{sample}.r2.fq',
		r1rv 		= workpath + 'quality_control/{sample}.r2.fq'
	output:
		merged_r1 	= workpath + 'trim_tail/{sample}.r1.fa',
		r1fw 		= workpath + 'trim_tail/{sample}.r1.fa',
		r2rv 		= workpath + 'trim_tail/{sample}.r1.fa',
		merged_r2 	= workpath + 'trim_tail/{sample}.r2.fa',
		r2fw 		= workpath + 'trim_tail/{sample}.r2.fa',
		r1rv 		= workpath + 'trim_tail/{sample}.r2.fa'
	params:
		fw_trim = config['trim']['fw'],
		rv_trim = config['trim']['rv']
	run:
		shell('seqtk trimfq -b {params.fw_trim} -e {params.rv_trim} {inpit.merged_r1} - | seqtk seq    -A -L 50 - > {output.merged_r1}')
		shell('seqtk trimfq -e {params.fw_trim} -b {params.rv_trim} {inpit.merged_r2} - | seqtk seq -r -A -L 50 - > {output.merged_r2}')
		shell('seqtk trimfq -b {params.fw_trim} {input.r1fw} - | seqtk seq    -A -L 50 - > {output.r1fw}')
		shell('seqtk trimfq -e {params.rv_trim} {input.r2rv} - | seqtk seq -r -A -L 50 - > {output.r2rv}')
		shell('seqtk trimfq -e {params.rv_trim} {input.r1rv} - | seqtk seq -r -A -L 50 - > {output.r1rv}')
		shell('seqtk trimfq -b {params.fw_trim} {input.r2fw} - | seqtk seq    -A -L 50 - > {output.r2fw}')

rule merge:
	input:
		merged_r1 	= workpath + 'trim_tail/{sample}.r1.fa',
		r1fw 		= workpath + 'trim_tail/{sample}.r1.fa',
		r2rv 		= workpath + 'trim_tail/{sample}.r1.fa',
		merged_r2 	= workpath + 'trim_tail/{sample}.r2.fa',
		r2fw 		= workpath + 'trim_tail/{sample}.r2.fa',
		r1rv 		= workpath + 'trim_tail/{sample}.r2.fa'
	output:
		merged	= workpath + 'merge/{sample}.merged.fa',
		fw 		= workpath + 'merge/{sample}.fw.fa',
		rv		= workpath + 'merge/{sample}.rv.fa'
	run:
		shell('cat {input.merged_r1} {input.merged_r2} > {output.merged}'}
		shell('cat {input.r1fw} {input.r2fw} > {output.fw}')
		shell('cat {input.r2rv} {input.r1rv} > {output.rv}')
		
rule alignment:
	input:
		merged	= workpath + 'merge/{sample}.merged.fa',
		fw 		= workpath + 'merge/{sample}.fw.fa',
		rv		= workpath + 'merge/{sample}.rv.fa'
	output:
		merged	= workpath + 'alignment/{sample}.merged.b6',
		fw 		= workpath + 'alignment/{sample}.fw.b6',
		rv		= workpath + 'alignment/{sample}.rv.b6',
		fwrv	= workpath + 'alignment/{sample}.fwrv.b6'
	params:
		acx  = config['database']['acx'],
		edx  = config['database']['edx'],
		mode = config['align']['mode'],
		id   = config['align']['id']
	run:
		shell('burst12 -q {input.merged} -a {params.acx} -r {params.edx} -o {output.merged} -i {params.id} -m {params.mode} -t {threads} > {log}')
		shell('burst12 -q {input.fw} -a {params.acx} -r {params.edx} -o {output.fw} -i {params.id} -m {params.mode} -t {threads} > {log}')
		shell('burst12 -q {input.rv} -a {params.acx} -r {params.edx} -o {output.rv} -i {params.id} -m {params.mode} -t {threads} > {log}')
		shell('amplicon_keepPairAln.py -i {output.fw},{output.rv} -o {output.fwrv} > {log}')
		
rule profiles:
	input:
		merged	= workpath + 'alignment/{sample}.merged.b6',
		fwrv	= workpath + 'alignment/{sample}.fwrv.b6'
	output:
		merged	= workpath + 'profiles/{sample}.merged.tsv',
		fwrv	= workpath + 'profiles/{sample}.fwrv.tsv'
		merged_biom	= workpath + 'profiles/{sample}.merged.biom',
		fwrv_biom	= workpath + 'profiles/{sample}.fwrv.biom'
	params:
		sampleName='{sample}'
	run:
		shell('amplicon_winnerTakeAll.py -i {input.merged} -sn {params.sampleName} -t {output.merged} -g > {log}')
		shell('biom convert -i {output.merged} -o {output.merged_biom} --to-json')
		shell('amplicon_winnerTakeAll.py -i {input.fwrv} -sn {params.sampleName} -t {output.fwrv} -g > {log}')
		shell('biom convert -i {output.fwrv} -o {output.fwrv_biom} --to-json')

rule count:
	input:
		r1fw = workpath + 'cutadapt/{sample}.r1fw.fq',
		r2fw = workpath + 'cutadapt/{sample}.r2fw.fq'	
		merged_r1 = workpath + 'merge_r1/{sample}.r1.assembled.fastq',
		r1fw = workpath + 'merge_r1/{sample}.r1.unassembled.forward.fastq',
		merged_r2 = workpath + 'merge_r2/{sample}.r2.assembled.fastq',
		r2fw = workpath + 'merge_r2/{sample}.r2.unassembled.forward.fastq',
		merged	= workpath + 'alignment/{sample}.merged.b6',
		fwrv	= workpath + 'alignment/{sample}.fwrv.b6'
	output:
	run:
		
rule concat:
	input:
		merged	= expand(workpath + 'profiles/{sample}.merged.biom', sample=SAMPLES),
		fwrv	= expand(orkpath + 'profiles/{sample}.fwrv.biom', sample=SAMPLES)
	output:
		combine_merged_biom			= workpath + 'concat/' + project + .merged.biom
		comebin_merged_taxa_biom	= workpath + 'concat/' + project + .merged.taxa.biom
		combine_merged_taxa_tsv		= workpath + 'concat/' + project + .merged.taxa.tsv
		combine_fwrv_biom			= workpath + 'concat/' + project + .fwrv.biom
		comebin_fwrv_taxa_biom		= workpath + 'concat/' + project + .fwrv.taxa.biom
		combine_fwrv_taxa_tsv		= workpath + 'concat/' + project + .fwrv.taxa.tsv
	params:
		taxa=config['database']['tax']
	log:
		workpath + 'logs/concat/concate.log'
	run:
		shell('amplicon_concat.py -i {input.merged} -biom_out {output.combine_merged_biom} > {log}')
		shell('biom add-metadata -i {output.combine_merged_biom} -o {comebin_merged_taxa_biom} --observation-metadata-fp {params.taxa} --observation-header OTUID,taxonomy --output-as-json --sc-separated taxonomy')
		shell('biom convert -i {comebin_merged_taxa_biom} -o {combine_merged_taxa_tsv} --to-tsv --header-key taxonomy')
		shell('amplicon_concat.py -i {input.fwrc} -biom_out {output.combine_fwrc_biom} > {log}')
		shell('biom add-metadata -i {output.combine_fwrc_biom} -o {comebin_fwrc_taxa_biom} --observation-metadata-fp {params.taxa} --observation-header OTUID,taxonomy --output-as-json --sc-separated taxonomy')
		shell('biom convert -i {comebin_fwrc_taxa_biom} -o {combine_fwrc_taxa_tsv} --to-tsv --header-key taxonomy')